# DITaR
[AAAI'26 oral] Official implementation of "Unbiased Rectification for Sequential Recommender Systems under Fake Orders (DITaR)"

## Overview
We propose DITaR (Dual-view Identification and Targeted Rectification), an efficient and unbiased framework designed to protect sequential recommender systems from fake ordersâ€”covertly manipulated interactions strategically embedded within genuine user sequences. First, we construct a Dual-view Identification (DI) module that leverages cross-view discrepancies between collaborative statistical patterns and semantic associations (enhanced by LLaMA2-7B) to detect suspicious interaction anomalies. Then, to avoid the indiscriminate removal of data, we employ an Influence Function to quantify the actual impact of detected samples, filtering out only truly harmful orders for Targeted Rectification (TaR) via gradient ascent. This targeted approach allows the system to neutralize negative biases while preserving beneficial information and sequence integrity without the prohibitive cost of retraining from scratch. Extensive experiments demonstrate that DITaR achieves superior recommendation quality and computational efficiency across multiple baselines.
<img src=".\assets\DITaR.png">

## Requirments
- python == 3.10.16
- pytorch == 2.6.0
- transformers == 4.51.3
- numpy == 2.2.6
- pandas == 2.2.3
- scikit-learn == 1.6.1     

## How to run
### DataProcess
This directory contains the data preprocessing scripts for the **ML-1M**, **Amazon-Beauty**, and **Yelp2018** datasets.
- `process_new.py`: The main script for data preprocessing.
- `add_poison.py`: The code used to inject noise/contamination into the preprocessed data.
- `poison.sh`: The shell script to execute the data poisoning process.

### train_models
This directory implements the frameworks, data loading, and training logic for three backbone models: **SASRec**, **GRU4Rec**, and **Bert4Rec**.
- Scripts: Execution scripts are located in the `/scripts` folder.
- Configuration: Supports flexible tuning of model architectures and training hyperparameters.
- Data Support: The models can be trained on: (1) Clean data (preprocessed); (2) Poisoned data (with injected attacks); (3) Retrain data (clean data generated by removing contaminated items).

### DualviewIdentification
Phase 1: Dual-view Identification This phase focuses on modeling a dual-view architecture to detect fake orders within the system.
#### DualviewModelConstruction
`DualviewConstruct`: The dual-view model is trained using a contaminated base model. The hyperparameter $\alpha$ is employed to balance the weights between semantic and collaborative views, while $\lambda_c$ adjusts the significance of the recommendation task. 

Execute `train.sh` to generate the dual-view model.
#### Identification
Utilizing the trained dual-view model, this module identifies fake orders across four dimensions. We specifically focus on the inconsistency between the dual-view representations and their corresponding predictions. A unified score is derived and subsequently smoothed to serve as the final evaluation criterion. 

Run `detect.sh` to extract the list of suspicious fake orders.
### TargetedRectification
Phase 2: Targeted Rectification This phase performs impact assessment and correction based on the results from Phase 1.
#### InfluenceEstimator
`InfluenceEstimator`: This component evaluates the identified suspicious orders to filter and pinpoint those that are genuinely detrimental to the model's performance.
#### SGA
`SelectiveGradientAscent`: To finalize the process, precise gradient ascent is applied to the harmful fake orders, effectively rectifying the model and mitigating the impact of malicious data.
